{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9532754,"sourceType":"datasetVersion","datasetId":5700442}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained('allenai/longformer-base-4096', clean_up_tokenization_spaces = True)\nmodel = AutoModelForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=2)  # Adjust num_labels as per your task\n\nprint(\"Model and Tokenizer loaded.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:02:36.962841Z","iopub.execute_input":"2024-10-08T06:02:36.963272Z","iopub.status.idle":"2024-10-08T06:02:49.578367Z","shell.execute_reply.started":"2024-10-08T06:02:36.963223Z","shell.execute_reply":"2024-10-08T06:02:49.577552Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eff931d1bf704d81a8cbb66175ff6b34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0457cfa2d6c547298e21ec44494bbd38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d8209721630403693f4588d9e659fc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12c99671648f4820b16b1a15774c4993"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f994e04fa7f84314ab33d7657ac16199"}},"metadata":{}},{"name":"stderr","text":"Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model and Tokenizer loaded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datasets import Dataset\nimport json\nimport pandas as pd\n\nreward = \"compre\" # relate, factual, compre\ndata_path = f'/kaggle/input/images/{reward}_error1.json'\n# Load the dataset\nwith open(data_path) as f:\n    dataset = json.load(f)\n\n# Convert to DataFrame\ndf = pd.DataFrame.from_dict(dataset, orient='index')\n# Inspect the DataFrame\nprint(df.head())\n# df = df.head(1000)\n\n# Convert DataFrame to Hugging Face Dataset\ndataset = Dataset.from_pandas(df[['combined', 'label']])  # Select relevant columns\n\n# Tokenization function\ndef tokenize_function(examples):\n    return tokenizer(\n        examples['combined'], \n        max_length=1024,\n        truncation=True, \n        padding='max_length',\n        return_tensors='pt'  # Return PyTorch tensors\n    )\n\n# Tokenize the dataset\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:02:52.767999Z","iopub.execute_input":"2024-10-08T06:02:52.768528Z","iopub.status.idle":"2024-10-08T06:02:57.211031Z","shell.execute_reply.started":"2024-10-08T06:02:52.768486Z","shell.execute_reply":"2024-10-08T06:02:57.210102Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                            combined  label\n0  **Text:**\\nTime is fast, and I have been buyin...      0\n1  **Text:**\\nIs the fuel consumption of the down...      1\n2  **Text:**\\nI usually love to see the informati...      1\n3  **Text:**\\nStill adhere to the way of \"the gol...      1\n4  **Text:**\\nUnconsciously, the four -wheel driv...      1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1798 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b97b18b0e604935a7d67f8aa4a531f0"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# Manually split the dataset into train and validation sets\nsplit_dataset = tokenized_dataset.train_test_split(test_size=0.001)  # Split the entire dataset (90% train, 10% validation)\n\n# Now you can access train and validation sets\ntrain_dataset = split_dataset['train']\nval_dataset = split_dataset['test']\nprint(len(train_dataset))\nprint(len(val_dataset))\nprint(\"split done\")","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:02:59.359734Z","iopub.execute_input":"2024-10-08T06:02:59.360926Z","iopub.status.idle":"2024-10-08T06:02:59.379894Z","shell.execute_reply.started":"2024-10-08T06:02:59.360873Z","shell.execute_reply":"2024-10-08T06:02:59.378971Z"},"trusted":true},"outputs":[{"name":"stdout","text":"1796\n2\nsplit done\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\nimport os\nos.environ[\"WANDB_MODE\"] = \"disabled\"\n\n# Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='/kaggle/working/results',\n    eval_strategy='epoch',\n    report_to=\"none\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=1,\n    per_device_eval_batch_size=1,\n    gradient_accumulation_steps=2,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    fp16=True,\n)\n\n# Initialize the Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)\n\n# Fine-tune the model\ntrainer.train()\n\n# bd91daf536563581acb815565de7dc1e2482c2df","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:03:02.981971Z","iopub.execute_input":"2024-10-08T06:03:02.982889Z","iopub.status.idle":"2024-10-08T06:52:47.768982Z","shell.execute_reply.started":"2024-10-08T06:03:02.982848Z","shell.execute_reply":"2024-10-08T06:52:47.767965Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\nInitializing global attention on CLS token...\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2245' max='2245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2245/2245 49:23, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>7.700913</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.300300</td>\n      <td>7.222042</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.409700</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.565200</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.417000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2245, training_loss=0.8734093205169474, metrics={'train_runtime': 2967.075, 'train_samples_per_second': 3.027, 'train_steps_per_second': 0.757, 'total_flos': 5898527472599040.0, 'train_loss': 0.8734093205169474, 'epoch': 5.0})"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"results = trainer.evaluate()\nprint(results)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:53:01.618761Z","iopub.execute_input":"2024-10-08T06:53:01.619806Z","iopub.status.idle":"2024-10-08T06:53:01.891133Z","shell.execute_reply.started":"2024-10-08T06:53:01.619757Z","shell.execute_reply":"2024-10-08T06:53:01.890223Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1/1 : < :]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"{'eval_loss': 5.9604641222676946e-08, 'eval_runtime': 0.2638, 'eval_samples_per_second': 7.581, 'eval_steps_per_second': 3.791, 'epoch': 5.0}\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Save the model and tokenizer\nsave_model_dir = f\"/kaggle/working/{reward}\"\nmodel.save_pretrained(save_model_dir)\ntokenizer.save_pretrained(save_model_dir)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:53:09.103003Z","iopub.execute_input":"2024-10-08T06:53:09.103377Z","iopub.status.idle":"2024-10-08T06:53:10.067027Z","shell.execute_reply.started":"2024-10-08T06:53:09.103338Z","shell.execute_reply":"2024-10-08T06:53:10.066028Z"},"trusted":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/compre/tokenizer_config.json',\n '/kaggle/working/compre/special_tokens_map.json',\n '/kaggle/working/compre/vocab.json',\n '/kaggle/working/compre/merges.txt',\n '/kaggle/working/compre/added_tokens.json',\n '/kaggle/working/compre/tokenizer.json')"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import shutil\n# destination_dir = \"/kaggle/working\"\n# Zip the model directory\nshutil.make_archive(save_model_dir, 'zip', save_model_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-08T06:53:17.908766Z","iopub.execute_input":"2024-10-08T06:53:17.909636Z","iopub.status.idle":"2024-10-08T06:54:07.736341Z","shell.execute_reply.started":"2024-10-08T06:53:17.909594Z","shell.execute_reply":"2024-10-08T06:54:07.735496Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/compre.zip'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}